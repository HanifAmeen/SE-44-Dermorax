{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/HanifAmeen/SE-44-Dermorax/blob/ML-Model--InceptionResNetV2/SDGP_CNN_Model_IRV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37_0sxULFnoP"
   },
   "source": [
    "Mounting the drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eBOQ6Q0EyObm",
    "outputId": "6a9487d0-197a-4403-e7b2-db1c1cd0f557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#mounting the drive \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w0QkMy3jOl0G",
    "outputId": "66ee4774-be6a-43eb-fd24-9ea916d56746"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 28 09:47:42 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   53C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MT7Fefmg84be"
   },
   "source": [
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ztvjoujZWHDX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer,InputSpec\n",
    "import keras.layers as kl\n",
    "from glob import glob\n",
    "from sklearn.metrics import auc\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras import callbacks \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (concatenate,Dense, Conv2D, MaxPooling2D, Flatten,Input,\n",
    "                                     Activation,add,AveragePooling2D,BatchNormalization,Dropout)\n",
    "import shutil\n",
    "from sklearn.metrics import  precision_score, recall_score, accuracy_score,classification_report\n",
    "from tensorflow.python.platform import build_info as tf_build_info\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:\\\\Users\\\\Janidu Chathumina\\\\Desktop\\\\Dataset\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuPiYN6lQBK_"
   },
   "source": [
    "#Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6VBYPMqdKos"
   },
   "source": [
    "##Initializing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Ai5YrzH-dWRn",
    "outputId": "629bc446-9ecd-49a1-fbb1-da5af6436490"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "        dataset  \n",
       "0  vidir_modern  \n",
       "1  vidir_modern  \n",
       "2  vidir_modern  \n",
       "3  vidir_modern  \n",
       "4  vidir_modern  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd = pd.read_csv(path+'HAM10000_metadata')\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "GlIqkLEX4q44",
    "outputId": "4da2fe91-8433-4d12-842e-ad27432e5e42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>6705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bkl</th>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vasc</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df</th>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dx\n",
       "nv     6705\n",
       "mel    1113\n",
       "bkl    1099\n",
       "bcc     514\n",
       "akiec   327\n",
       "vasc    142\n",
       "df      115"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#counting the images per each class\n",
    "def count_images_on_type(series):\n",
    "    display(pd.DataFrame(series.value_counts()))\n",
    "\n",
    "#class_list = ['akiec','bcc','bkl','df','mel','nv','vasc']\n",
    "count_images_on_type(data_pd['dx'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HWKlHqVT3JvR"
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join('HAM10000', 'train_dir')\n",
    "\n",
    "test_dir = os.path.join('HAM10000', 'test_dir')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkYoqu3IHM2D"
   },
   "outputs": [],
   "source": [
    "\n",
    "#making the directories to store test and train data\n",
    "os.mkdir(path+'train_dir')\n",
    "os.mkdir(path+'test_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "c0p_1ukLEwYT",
    "outputId": "2480b343-e7b5-4079-fdba-6330de6ceedc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lesion_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HAM_0000000</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAM_0000001</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAM_0000002</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAM_0000003</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAM_0000004</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  dx  dx_type  age  sex  localization  dataset\n",
       "lesion_id                                                          \n",
       "HAM_0000000         2   2        2    2    2             2        2\n",
       "HAM_0000001         1   1        1    1    1             1        1\n",
       "HAM_0000002         3   3        3    3    3             3        3\n",
       "HAM_0000003         1   1        1    1    1             1        1\n",
       "HAM_0000004         1   1        1    1    1             1        1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count = data_pd.groupby('lesion_id').count()\n",
    "df_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ntcDa-qAEpQ4",
    "outputId": "50edb885-9396-49a6-ede7-602be358229e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  image_id  dx  dx_type  age  sex  localization  dataset\n",
       "0  HAM_0000001         1   1        1    1    1             1        1\n",
       "1  HAM_0000003         1   1        1    1    1             1        1\n",
       "2  HAM_0000004         1   1        1    1    1             1        1\n",
       "3  HAM_0000007         1   1        1    1    1             1        1\n",
       "4  HAM_0000008         1   1        1    1    1             1        1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count = df_count[df_count['dx'] == 1]\n",
    "df_count.reset_index(inplace=True)\n",
    "df_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GPg-AXTxQkv0",
    "outputId": "03e8b093-5104-42ab-cdc8-eac2e8a91aed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>duplicate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>duplicate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>duplicate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>duplicate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>duplicate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "        dataset is_duplicate  \n",
       "0  vidir_modern    duplicate  \n",
       "1  vidir_modern    duplicate  \n",
       "2  vidir_modern    duplicate  \n",
       "3  vidir_modern    duplicate  \n",
       "4  vidir_modern    duplicate  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding the duplicates to make sure none of these images have augmented duplicates\n",
    "\n",
    "def duplicates(x):\n",
    "    unique = set(df_count['lesion_id'])\n",
    "    if x in unique:\n",
    "        return 'no' \n",
    "    else:\n",
    "        return 'duplicate'\n",
    "\n",
    "data_pd['is_duplicate'] = data_pd['lesion_id'].apply(duplicates)\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TpJELKrRxMQ",
    "outputId": "499be530-c322-4401-be82-e342ef63e0a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         lesion_id      image_id     dx dx_type   age     sex localization  \\\n",
      "10     HAM_0001396  ISIC_0025276    bkl   histo  55.0  female        trunk   \n",
      "15     HAM_0007207  ISIC_0031326    bkl   histo  65.0    male         back   \n",
      "20     HAM_0006071  ISIC_0032343    bkl   histo  70.0  female         face   \n",
      "33     HAM_0005612  ISIC_0024981    bkl   histo  80.0    male        scalp   \n",
      "34     HAM_0005388  ISIC_0027815    bkl   histo  80.0    male        chest   \n",
      "...            ...           ...    ...     ...   ...     ...          ...   \n",
      "9988   HAM_0001036  ISIC_0027588  akiec   histo  50.0  female         face   \n",
      "9990   HAM_0004462  ISIC_0027334  akiec   histo  45.0    male        trunk   \n",
      "9991   HAM_0001152  ISIC_0030133  akiec   histo  65.0    male         face   \n",
      "10001  HAM_0000020  ISIC_0031922  akiec   histo  60.0  female         face   \n",
      "10008  HAM_0001576  ISIC_0033705  akiec   histo  60.0    male         face   \n",
      "\n",
      "            dataset is_duplicate  \n",
      "10     vidir_modern           no  \n",
      "15     vidir_modern           no  \n",
      "20     vidir_modern           no  \n",
      "33     vidir_modern           no  \n",
      "34        rosendahl           no  \n",
      "...             ...          ...  \n",
      "9988      rosendahl           no  \n",
      "9990   vidir_modern           no  \n",
      "9991      rosendahl           no  \n",
      "10001     rosendahl           no  \n",
      "10008  vidir_modern           no  \n",
      "\n",
      "[5514 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#framing all the meta data\n",
    "df_count = data_pd[data_pd['is_duplicate'] == 'no']\n",
    "print(df_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9kQjlAnSc5a"
   },
   "source": [
    "##Test Train Split 15% to 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UsW38Kg4SReP"
   },
   "outputs": [],
   "source": [
    "train, test_df = train_test_split(df_count, test_size=0.15, stratify=df_count['dx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "U71SWJLgU0Fg"
   },
   "outputs": [],
   "source": [
    "#labels the data as test or train\n",
    "def identify_trainOrtest(x):\n",
    "    test_data = set(test_df['image_id'])\n",
    "    if str(x) in test_data:\n",
    "        return 'test'\n",
    "    else:\n",
    "        return 'train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "nLlMTv6MVjv1",
    "outputId": "0732f1ac-1ba4-4fad-d742-e6c292c9b918"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4407</th>\n",
       "      <td>HAM_0004436</td>\n",
       "      <td>ISIC_0030042</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5886</th>\n",
       "      <td>HAM_0001382</td>\n",
       "      <td>ISIC_0028922</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5919</th>\n",
       "      <td>HAM_0002183</td>\n",
       "      <td>ISIC_0031912</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6384</th>\n",
       "      <td>HAM_0000567</td>\n",
       "      <td>ISIC_0029677</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>trunk</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>HAM_0007118</td>\n",
       "      <td>ISIC_0027856</td>\n",
       "      <td>vasc</td>\n",
       "      <td>consensus</td>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>trunk</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id      image_id    dx    dx_type   age     sex  \\\n",
       "4407  HAM_0004436  ISIC_0030042    nv  follow_up  45.0  female   \n",
       "5886  HAM_0001382  ISIC_0028922    nv  follow_up  80.0    male   \n",
       "5919  HAM_0002183  ISIC_0031912    nv  follow_up  65.0    male   \n",
       "6384  HAM_0000567  ISIC_0029677    nv  follow_up  35.0    male   \n",
       "2432  HAM_0007118  ISIC_0027856  vasc  consensus  45.0  female   \n",
       "\n",
       "         localization        dataset is_duplicate  \n",
       "4407          abdomen  vidir_molemax           no  \n",
       "5886  lower extremity  vidir_molemax           no  \n",
       "5919             back  vidir_molemax           no  \n",
       "6384            trunk  vidir_molemax           no  \n",
       "2432            trunk  vidir_molemax           no  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_5ynJKAiWK2Z",
    "outputId": "761f41fb-8783-496b-ca39-944f0f22fda7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>train_test_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>duplicate</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>duplicate</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>duplicate</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>duplicate</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>duplicate</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "        dataset is_duplicate train_test_split  \n",
       "0  vidir_modern    duplicate            train  \n",
       "1  vidir_modern    duplicate            train  \n",
       "2  vidir_modern    duplicate            train  \n",
       "3  vidir_modern    duplicate            train  \n",
       "4  vidir_modern    duplicate            train  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating train_df\n",
    "data_pd['train_test_split'] = data_pd['image_id'].apply(identify_trainOrtest)\n",
    "train_df = data_pd[data_pd['train_test_split'] == 'train']\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sthlyxfhWe7k"
   },
   "outputs": [],
   "source": [
    "# adding to lists by image id of train and test images\n",
    "train_list = list(train_df['image_id'])\n",
    "test_list = list(test_df['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYGd_JeEWrH2",
    "outputId": "8b2282d2-f2a9-4e1c-d87a-3693823e0384"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9187"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31QHr96pW2sx",
    "outputId": "cfc66f67-5415-4f62-f369-c742106cf0c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "828"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "sreWEQXOXFes"
   },
   "outputs": [],
   "source": [
    "# Set the image_id as the index in data_pd\n",
    "data_pd.set_index('image_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "BniXcQjEZDiE"
   },
   "outputs": [],
   "source": [
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRavcyioYPFS"
   },
   "outputs": [],
   "source": [
    "#making the directories per each cancer type in test and train dir \n",
    "for i in targetnames:\n",
    "  os.mkdir(path+\"test_dir\\\\\"+i)\n",
    "  os.mkdir(path+\"train_dir\\\\\"+i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBwEFrJjHuBa"
   },
   "source": [
    "###Copying the images to the test and the train folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7gfv13pYbPp"
   },
   "outputs": [],
   "source": [
    "#compying images to train folders\n",
    "for image in train_list:\n",
    "    file_name = image+'.jpg'\n",
    "    label = data_pd.loc[image, 'dx']\n",
    "\n",
    "    # path of source image \n",
    "    source = os.path.join(path+'HAM10000\\\\',file_name)\n",
    "\n",
    "    # copying the image from the source to target file\n",
    "    target = os.path.join(path+'train_dir\\\\',label,file_name) \n",
    "\n",
    "    shutil.copyfile(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7N4jKXr34jT"
   },
   "outputs": [],
   "source": [
    "#copying images to the test folders\n",
    "for image in test_list:\n",
    "\n",
    "    file_name = image+'.jpg'\n",
    "    label = data_pd.loc[image, 'dx']\n",
    "\n",
    "    # path of source image \n",
    "    source = os.path.join(path+'HAM10000\\\\',file_name)\n",
    "\n",
    "    # copying the image from the source to target file\n",
    "    target = os.path.join(path+'test_dir\\\\',label,file_name)\n",
    "\n",
    "    shutil.copyfile(source, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTQ4l4u7IMzJ"
   },
   "source": [
    "##Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oeikPTlbYEPz",
    "outputId": "11af9d6b-2196-4b02-a558-6b69848b899c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 images belonging to 1 classes.\n",
      "Found 488 images belonging to 1 classes.\n",
      "Found 1033 images belonging to 1 classes.\n",
      "Found 109 images belonging to 1 classes.\n",
      "Found 1079 images belonging to 1 classes.\n",
      "Found 6042 images belonging to 1 classes.\n",
      "Found 132 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "\n",
    "# Augmenting images and storing them in temporary directories \n",
    "for img_class in targetnames:\n",
    "\n",
    "    #creating temporary directories\n",
    "    # creating a base directory\n",
    "    \n",
    "    os.mkdir(path+'aug_dir')\n",
    "    # creating a subdirectory inside the base directory for images of the same class\n",
    "    img_dir = os.path.join('aug_dir', 'img_dir')\n",
    "    os.mkdir(path+'aug_dir\\\\img_dir')\n",
    "\n",
    "    img_list = os.listdir(path+'train_dir\\\\' + img_class)\n",
    "\n",
    "    # Copy images from the class train_dir to the img_dir \n",
    "    for file_name in img_list:\n",
    "\n",
    "        # path of source image in training directory\n",
    "        source = os.path.join(path+'train_dir\\\\',img_class, file_name)\n",
    "\n",
    "        # creating a target directory to send images \n",
    "        target = os.path.join(path+'aug_dir\\\\img_dir\\\\',file_name)\n",
    "\n",
    "        # copying the image from the source to target file\n",
    "        shutil.copyfile(source, target)\n",
    "\n",
    "    # Temporary augumented dataset directory.\n",
    "    source_path = path+'aug_dir\\\\'\n",
    "\n",
    "    # Augmented images will be saved to training directory\n",
    "    save_path = path+'train_dir\\\\'+img_class\n",
    "\n",
    "    # Creating Image Data Generator to augment images\n",
    "    # Rotating,flipping and shifting the images to create augmented images.\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest'\n",
    "\n",
    "    )\n",
    "\n",
    "    batch_size = 50\n",
    "\n",
    "    aug_datagen = datagen.flow_from_directory(source_path,\n",
    "                                              save_to_dir=save_path,\n",
    "                                              save_format='jpg',\n",
    "                                              target_size=(224, 224),\n",
    "                                              batch_size=batch_size)\n",
    "\n",
    "    # Generate the augmented images\n",
    "    aug_images = 8000 \n",
    "\n",
    "    num_files = len(os.listdir(path+'aug_dir\\\\img_dir\\\\'))\n",
    "    num_batches = int(np.ceil((aug_images - num_files) / batch_size))\n",
    "\n",
    "    # creating 8000 augmented images per class\n",
    "    for i in range(0, num_batches):\n",
    "        images, labels = next(aug_datagen)\n",
    "\n",
    "    # delete temporary directory \n",
    "    shutil.rmtree(path+'aug_dir')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "D32TO5IOjmFA"
   },
   "outputs": [],
   "source": [
    "train_path = path+'train_dir'\n",
    "test_path = path+'test_dir'\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "-0nmy78gjrFw"
   },
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ra_646GklwwD",
    "outputId": "fdb8dfeb-04f6-44c7-fb9f-b229bf5cb296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Batches: \n",
      "Found 51699 images belonging to 7 classes.\n",
      "\n",
      "Test Batches: \n",
      "Found 828 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "#To find the total number of images in the training batch and test batch.\n",
    "image_size = 299\n",
    "print(\"\\nTrain Batches: \")\n",
    "train_batches = datagen.flow_from_directory(directory=train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "print(\"\\nTest Batches: \")\n",
    "test_batches =datagen.flow_from_directory(test_path,\n",
    "                                           target_size=(image_size,image_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQ2NBFRRdXJ_"
   },
   "source": [
    "#Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dTOS5Wx-nCD"
   },
   "source": [
    "##Downloading the InceptionResNetV2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "tKSzDPQq7ltJ"
   },
   "outputs": [],
   "source": [
    "irv2 = tf.keras.applications.InceptionResNetV2(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classifier_activation=\"softmax\",\n",
    "\n",
    ")\n",
    "\n",
    "# Excluding the last 28 layers of the model.\n",
    "#To implement the own layers for the skin cancer classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uy2RGplfSglU",
    "outputId": "59059358-bdaa-4934-dd56-c8a58fe7fb64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of layers in irv2 model\n",
    "len(irv2.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P5q1CM3CUGOo",
    "outputId": "17fd504f-df04-401b-f665-507b97d7c76b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x203cd3da520>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203cd3eee50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203cd3eefa0>,\n",
       " <keras.layers.core.Activation at 0x203cd482910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203cd3ce460>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203cd46d1f0>,\n",
       " <keras.layers.core.Activation at 0x203cd3fb430>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203bb5e7f70>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203bb5e1e20>,\n",
       " <keras.layers.core.Activation at 0x203bb5e1d90>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x203bb3c58e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203bbaf2ee0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203bbb10400>,\n",
       " <keras.layers.core.Activation at 0x203bbb10eb0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203bb681970>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203bbb0dfa0>,\n",
       " <keras.layers.core.Activation at 0x203bcb6c550>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x203bcc6a250>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203cd432df0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203cd482250>,\n",
       " <keras.layers.core.Activation at 0x203cd365100>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203bcc11af0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203cd3cb9d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203bccbf700>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203c4d8d340>,\n",
       " <keras.layers.core.Activation at 0x203bccd2c70>,\n",
       " <keras.layers.core.Activation at 0x203c4d8d070>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x203bcb535b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203bcc670d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203cd3cfbe0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203c4c69730>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203bccc71c0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203bcb48eb0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ddd99280>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203cd2ecf40>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203bb60f880>,\n",
       " <keras.layers.core.Activation at 0x203bcb481f0>,\n",
       " <keras.layers.core.Activation at 0x203ddd99430>,\n",
       " <keras.layers.core.Activation at 0x203c4cc8430>,\n",
       " <keras.layers.core.Activation at 0x203bcbc9ac0>,\n",
       " <keras.layers.merge.Concatenate at 0x203bccd7dc0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203bcbf7a30>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203bcb93220>,\n",
       " <keras.layers.core.Activation at 0x203bcb1bdf0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203c07e1d60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203bcb88040>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203bd5d2550>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203bb675520>,\n",
       " <keras.layers.core.Activation at 0x203bd5e7700>,\n",
       " <keras.layers.core.Activation at 0x203bb6756d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203c090f730>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203bccaf9a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203b9d66640>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203c08a4e50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203bcbeff40>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ba1c7cd0>,\n",
       " <keras.layers.core.Activation at 0x203c08a40d0>,\n",
       " <keras.layers.core.Activation at 0x203bcbfe6d0>,\n",
       " <keras.layers.core.Activation at 0x203b920da00>,\n",
       " <keras.layers.merge.Concatenate at 0x203bb66a0d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203bcc3b070>,\n",
       " <keras.layers.core.Lambda at 0x203bcba2040>,\n",
       " <keras.layers.core.Activation at 0x203c0775190>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebd84970>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebd92610>,\n",
       " <keras.layers.core.Activation at 0x203ebd8ddc0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203cd486400>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebd9cf10>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ba4eb9a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebda3160>,\n",
       " <keras.layers.core.Activation at 0x203b91031f0>,\n",
       " <keras.layers.core.Activation at 0x203ebda3850>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203b715b220>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203b9103d60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebdadd60>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203b93073d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203b910ba90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebdb7fd0>,\n",
       " <keras.layers.core.Activation at 0x203cd442160>,\n",
       " <keras.layers.core.Activation at 0x203b910bc10>,\n",
       " <keras.layers.core.Activation at 0x203ebdc27f0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ebdb77f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebdc7580>,\n",
       " <keras.layers.core.Lambda at 0x203ebdc2670>,\n",
       " <keras.layers.core.Activation at 0x203ebdb7cd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebdd7dc0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebdd9550>,\n",
       " <keras.layers.core.Activation at 0x203bcc52820>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203b9102550>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebde0f70>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebd82d60>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebdf23a0>,\n",
       " <keras.layers.core.Activation at 0x203ebd928e0>,\n",
       " <keras.layers.core.Activation at 0x203ebdec1c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebd9c2e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203bbb06e50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebdfbf70>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebdcda90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebdd6940>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebe01b50>,\n",
       " <keras.layers.core.Activation at 0x203ebd8db50>,\n",
       " <keras.layers.core.Activation at 0x203c08aa670>,\n",
       " <keras.layers.core.Activation at 0x203ebe012b0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ebe06b50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebe13790>,\n",
       " <keras.layers.core.Lambda at 0x203ebe0bcd0>,\n",
       " <keras.layers.core.Activation at 0x203ebe0b9a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ba4eb040>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebe36e50>,\n",
       " <keras.layers.core.Activation at 0x203ebda8e20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebe2e4f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebe381c0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebe01220>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebe3edc0>,\n",
       " <keras.layers.core.Activation at 0x203ebe063a0>,\n",
       " <keras.layers.core.Activation at 0x203ebe3ef40>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebe179a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebde7580>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebe403a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebe32220>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203cd2715e0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebe51910>,\n",
       " <keras.layers.core.Activation at 0x203ebe323a0>,\n",
       " <keras.layers.core.Activation at 0x203ebddc3d0>,\n",
       " <keras.layers.core.Activation at 0x203ebe4d0a0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ebe588e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebe60220>,\n",
       " <keras.layers.core.Lambda at 0x203ebe6d2b0>,\n",
       " <keras.layers.core.Activation at 0x203ebe65f10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebe707f0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203b9102ee0>,\n",
       " <keras.layers.core.Activation at 0x203ba4d4760>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebe8a100>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebdd5340>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebe8aa90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebe91ac0>,\n",
       " <keras.layers.core.Activation at 0x203ebe84160>,\n",
       " <keras.layers.core.Activation at 0x203ebe91580>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebe70550>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebe65ee0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebe93af0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebe7e280>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebe454c0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebe94ac0>,\n",
       " <keras.layers.core.Activation at 0x203ebe70b20>,\n",
       " <keras.layers.core.Activation at 0x203ebe450d0>,\n",
       " <keras.layers.core.Activation at 0x203ebe966a0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ebe9db20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebe9d520>,\n",
       " <keras.layers.core.Lambda at 0x203ebea9d60>,\n",
       " <keras.layers.core.Activation at 0x203ebea3760>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebee0820>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebe9d460>,\n",
       " <keras.layers.core.Activation at 0x203ebe98430>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebebddf0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebdf2a90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebeca8b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebe60d60>,\n",
       " <keras.layers.core.Activation at 0x203ebed00a0>,\n",
       " <keras.layers.core.Activation at 0x203ebe91c40>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebeadeb0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebed09d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebe58250>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebea9ca0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebedec40>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebeeb9d0>,\n",
       " <keras.layers.core.Activation at 0x203ebe9dc70>,\n",
       " <keras.layers.core.Activation at 0x203ebede400>,\n",
       " <keras.layers.core.Activation at 0x203ebeee2e0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ebeee640>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebeea4c0>,\n",
       " <keras.layers.core.Lambda at 0x203ebefe5e0>,\n",
       " <keras.layers.core.Activation at 0x203ebef69d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebf40e50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebf407f0>,\n",
       " <keras.layers.core.Activation at 0x203ebf3a190>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebf066a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebf2eca0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebf16eb0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebf06580>,\n",
       " <keras.layers.core.Activation at 0x203ebf16e20>,\n",
       " <keras.layers.core.Activation at 0x203ebf06df0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebf02c40>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebf282e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebe7edf0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebf11fd0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebf34f40>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebee7520>,\n",
       " <keras.layers.core.Activation at 0x203ebf11220>,\n",
       " <keras.layers.core.Activation at 0x203ebf34190>,\n",
       " <keras.layers.core.Activation at 0x203ebf02bb0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ebea9580>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebf44ca0>,\n",
       " <keras.layers.core.Lambda at 0x203ebf4d820>,\n",
       " <keras.layers.core.Activation at 0x203ebef10a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebf7dca0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebf89f10>,\n",
       " <keras.layers.core.Activation at 0x203ebf925e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebf53e50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebf84940>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebf68550>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebf92ee0>,\n",
       " <keras.layers.core.Activation at 0x203ebf5d2e0>,\n",
       " <keras.layers.core.Activation at 0x203ebf92b80>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebf4ef70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebf6be20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebf9e4c0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebf4ba90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebf71280>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebf5d430>,\n",
       " <keras.layers.core.Activation at 0x203ebf4bc10>,\n",
       " <keras.layers.core.Activation at 0x203ebf71880>,\n",
       " <keras.layers.core.Activation at 0x203ebf761c0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ebf4e6d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebeee310>,\n",
       " <keras.layers.core.Lambda at 0x203ebf4daf0>,\n",
       " <keras.layers.core.Activation at 0x203ebefeca0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebfb8eb0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebfcaa00>,\n",
       " <keras.layers.core.Activation at 0x203ebfca490>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebfad490>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebfde700>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebfa9760>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebfe92e0>,\n",
       " <keras.layers.core.Activation at 0x203ebfac940>,\n",
       " <keras.layers.core.Activation at 0x203ebfe30d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebfa6d30>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebfb80d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebff68b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebfa9f70>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebfc50a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebfeab20>,\n",
       " <keras.layers.core.Activation at 0x203ebfa91c0>,\n",
       " <keras.layers.core.Activation at 0x203ebfc51f0>,\n",
       " <keras.layers.core.Activation at 0x203ebff66a0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ebfca820>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebfbe940>,\n",
       " <keras.layers.core.Lambda at 0x203ebea3ee0>,\n",
       " <keras.layers.core.Activation at 0x203cd473790>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec0068b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec015b20>,\n",
       " <keras.layers.core.Activation at 0x203ec006220>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebf9ee80>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec015280>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebf762e0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec010850>,\n",
       " <keras.layers.core.Activation at 0x203ebef1a90>,\n",
       " <keras.layers.core.Activation at 0x203ec010940>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebf40dc0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebf53a00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec02c220>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebfadeb0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec009190>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec03fbe0>,\n",
       " <keras.layers.core.Activation at 0x203cd40dac0>,\n",
       " <keras.layers.core.Activation at 0x203ebfb80a0>,\n",
       " <keras.layers.core.Activation at 0x203ec02c2b0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec03f2b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ddd997f0>,\n",
       " <keras.layers.core.Lambda at 0x203ec061550>,\n",
       " <keras.layers.core.Activation at 0x203ec061f70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec031dc0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec046a60>,\n",
       " <keras.layers.core.Activation at 0x203ec0492e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebf71910>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec05a5b0>,\n",
       " <keras.layers.core.Activation at 0x203ec031f40>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec03f730>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ebf71a90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec0531f0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ebf532e0>,\n",
       " <keras.layers.core.Activation at 0x203ec046e50>,\n",
       " <keras.layers.core.Activation at 0x203ebf7d520>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x203ec069460>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec001af0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec06d460>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec073d30>,\n",
       " <keras.layers.core.Activation at 0x203ec071d00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec073760>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec0822b0>,\n",
       " <keras.layers.core.Activation at 0x203ec0718e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec049d90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec096280>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec06d1f0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec08f6d0>,\n",
       " <keras.layers.core.Activation at 0x203ec0239a0>,\n",
       " <keras.layers.core.Activation at 0x203ec0b9fa0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec0b9d90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec09b490>,\n",
       " <keras.layers.core.Lambda at 0x203ec08fc70>,\n",
       " <keras.layers.core.Activation at 0x203ec0b94c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec0b91c0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec0383d0>,\n",
       " <keras.layers.core.Activation at 0x203ec087250>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec069b80>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec053b80>,\n",
       " <keras.layers.core.Activation at 0x203ebf52d60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec09b6a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec0c3370>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec07ce20>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec0bedc0>,\n",
       " <keras.layers.core.Activation at 0x203ec0a4580>,\n",
       " <keras.layers.core.Activation at 0x203ec0c3640>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec0ca0a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec0b9040>,\n",
       " <keras.layers.core.Lambda at 0x203ec0dc1f0>,\n",
       " <keras.layers.core.Activation at 0x203ec0e44f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec0e4220>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec0f5670>,\n",
       " <keras.layers.core.Activation at 0x203ec0f2d60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec119a00>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec1193a0>,\n",
       " <keras.layers.core.Activation at 0x203ec119b50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec0ebbb0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec1191f0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec0f2340>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec10a040>,\n",
       " <keras.layers.core.Activation at 0x203ec0ca130>,\n",
       " <keras.layers.core.Activation at 0x203ec1194c0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec0cafd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec0dc3d0>,\n",
       " <keras.layers.core.Lambda at 0x203ec03ff70>,\n",
       " <keras.layers.core.Activation at 0x203ec0ca640>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec0d42b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec07c0d0>,\n",
       " <keras.layers.core.Activation at 0x203ec0c3f10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec12d3a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec12aa00>,\n",
       " <keras.layers.core.Activation at 0x203ec128ac0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec009c10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec1416a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec0d49d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec130370>,\n",
       " <keras.layers.core.Activation at 0x203ec112b20>,\n",
       " <keras.layers.core.Activation at 0x203ec12d610>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec141040>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec0f5340>,\n",
       " <keras.layers.core.Lambda at 0x203ec156d60>,\n",
       " <keras.layers.core.Activation at 0x203ec14e2b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec14ea90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec17d490>,\n",
       " <keras.layers.core.Activation at 0x203ec17d520>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec171a60>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec15d7f0>,\n",
       " <keras.layers.core.Activation at 0x203ec171f10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec16aa60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec16a9a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec15d670>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec15df10>,\n",
       " <keras.layers.core.Activation at 0x203ec141070>,\n",
       " <keras.layers.core.Activation at 0x203ec1775b0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec0ffcd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec14e670>,\n",
       " <keras.layers.core.Lambda at 0x203ec0f5f70>,\n",
       " <keras.layers.core.Activation at 0x203ec0ff0a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec0c6b50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec18ca60>,\n",
       " <keras.layers.core.Activation at 0x203ec18edf0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec18c0a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec19ca90>,\n",
       " <keras.layers.core.Activation at 0x203ec18e160>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec18e340>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec1a9970>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec1963a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec1af340>,\n",
       " <keras.layers.core.Activation at 0x203ec009160>,\n",
       " <keras.layers.core.Activation at 0x203ec1a9370>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec1bf820>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec0c6b80>,\n",
       " <keras.layers.core.Lambda at 0x203ec1e51c0>,\n",
       " <keras.layers.core.Activation at 0x203ec1e5d00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec1d0040>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec1daf70>,\n",
       " <keras.layers.core.Activation at 0x203ec1dcc70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec1cb250>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec14edf0>,\n",
       " <keras.layers.core.Activation at 0x203ec1c2d00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec1e57f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec1afe80>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec1bfbe0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec0d46a0>,\n",
       " <keras.layers.core.Activation at 0x203ec1d0580>,\n",
       " <keras.layers.core.Activation at 0x203ec19c790>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec1ea7f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec1cb970>,\n",
       " <keras.layers.core.Lambda at 0x203ec1f1e20>,\n",
       " <keras.layers.core.Activation at 0x203ec1f1c70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec1f18e0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec1f12e0>,\n",
       " <keras.layers.core.Activation at 0x203ec208fa0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec1fcd00>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec218a90>,\n",
       " <keras.layers.core.Activation at 0x203ec208df0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec208850>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec222970>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec210820>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec245520>,\n",
       " <keras.layers.core.Activation at 0x203ec1ea8b0>,\n",
       " <keras.layers.core.Activation at 0x203ec245250>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec238820>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec218520>,\n",
       " <keras.layers.core.Lambda at 0x203ec22af70>,\n",
       " <keras.layers.core.Activation at 0x203ec23cd00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec23c0a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec161940>,\n",
       " <keras.layers.core.Activation at 0x203ec1f68b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec1efa60>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec1961f0>,\n",
       " <keras.layers.core.Activation at 0x203ec1eaa90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec177190>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec256370>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec1fc400>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec24f280>,\n",
       " <keras.layers.core.Activation at 0x203ec22a100>,\n",
       " <keras.layers.core.Activation at 0x203ec24c040>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec2563d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec245970>,\n",
       " <keras.layers.core.Lambda at 0x203ec276460>,\n",
       " <keras.layers.core.Activation at 0x203ec26b550>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec26ba30>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec284280>,\n",
       " <keras.layers.core.Activation at 0x203ec27ea00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec28b370>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec2a6b80>,\n",
       " <keras.layers.core.Activation at 0x203ec2a6a00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec2707f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec29f9a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec2709a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec298f40>,\n",
       " <keras.layers.core.Activation at 0x203ec2569d0>,\n",
       " <keras.layers.core.Activation at 0x203ec29f100>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec270a00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec2625b0>,\n",
       " <keras.layers.core.Lambda at 0x203ec1613d0>,\n",
       " <keras.layers.core.Activation at 0x203ec270370>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec2b7370>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec284940>,\n",
       " <keras.layers.core.Activation at 0x203ec139070>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec2b8f40>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec2b5280>,\n",
       " <keras.layers.core.Activation at 0x203ec2b7280>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec1eabe0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec2bc9a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec1ef8e0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec2c3160>,\n",
       " <keras.layers.core.Activation at 0x203ec2ac040>,\n",
       " <keras.layers.core.Activation at 0x203ec2bc220>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec2cf8e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec2842b0>,\n",
       " <keras.layers.core.Lambda at 0x203ec2ddbb0>,\n",
       " <keras.layers.core.Activation at 0x203ec2c6ca0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec2e3340>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec30bb80>,\n",
       " <keras.layers.core.Activation at 0x203ec30bb20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec311190>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec2ef400>,\n",
       " <keras.layers.core.Activation at 0x203ec2cf670>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec2f68b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec2e3f40>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec2ef640>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec2eabb0>,\n",
       " <keras.layers.core.Activation at 0x203ec2c3e50>,\n",
       " <keras.layers.core.Activation at 0x203ec311310>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec2c6520>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec2dda30>,\n",
       " <keras.layers.core.Lambda at 0x203ec24c8e0>,\n",
       " <keras.layers.core.Activation at 0x203ec2511f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec251a90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec31ba00>,\n",
       " <keras.layers.core.Activation at 0x203ec314ee0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec330bb0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec330100>,\n",
       " <keras.layers.core.Activation at 0x203ec32b820>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec31ea30>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec334490>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec314a00>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec34cfa0>,\n",
       " <keras.layers.core.Activation at 0x203ec2e3e20>,\n",
       " <keras.layers.core.Activation at 0x203ec3342b0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec350250>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec24ce50>,\n",
       " <keras.layers.core.Lambda at 0x203ec374c40>,\n",
       " <keras.layers.core.Activation at 0x203ec3742b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec359280>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec32ba90>,\n",
       " <keras.layers.core.Activation at 0x203ec369f10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec366d00>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec369610>,\n",
       " <keras.layers.core.Activation at 0x203ec3593a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec374fa0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec31b6d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec3505b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec3147c0>,\n",
       " <keras.layers.core.Activation at 0x203ec350460>,\n",
       " <keras.layers.core.Activation at 0x203ec31b0d0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec37abe0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec359d30>,\n",
       " <keras.layers.core.Lambda at 0x203ec381f40>,\n",
       " <keras.layers.core.Activation at 0x203ec3811f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec381ca0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec38f250>,\n",
       " <keras.layers.core.Activation at 0x203ec38b7c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec3abbb0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec3ab100>,\n",
       " <keras.layers.core.Activation at 0x203ec3a6820>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec3956a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec3b1490>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec38be20>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec3cdfa0>,\n",
       " <keras.layers.core.Activation at 0x203ec37aa60>,\n",
       " <keras.layers.core.Activation at 0x203ec3cdfd0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec3cd250>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec3b9100>,\n",
       " <keras.layers.core.Lambda at 0x203ec3b93d0>,\n",
       " <keras.layers.core.Activation at 0x203ec3c5670>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec3c5dc0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec395f10>,\n",
       " <keras.layers.core.Activation at 0x203ec3954c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec359070>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec31b1c0>,\n",
       " <keras.layers.core.Activation at 0x203ec2fd3a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec3c5430>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec3e1490>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec3bee20>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec3da190>,\n",
       " <keras.layers.core.Activation at 0x203ec3cd460>,\n",
       " <keras.layers.core.Activation at 0x203ec3e1550>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec3e66a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec3d3d30>,\n",
       " <keras.layers.core.Lambda at 0x203ec3e6280>,\n",
       " <keras.layers.core.Activation at 0x203ec3fe640>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec3fe370>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec426040>,\n",
       " <keras.layers.core.Activation at 0x203ec40bd60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec435b20>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec4354c0>,\n",
       " <keras.layers.core.Activation at 0x203ec4351f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec406640>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec420940>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec40b7c0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec40b040>,\n",
       " <keras.layers.core.Activation at 0x203ec3e6640>,\n",
       " <keras.layers.core.Activation at 0x203ec4355e0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec43c130>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec3f7520>,\n",
       " <keras.layers.core.Lambda at 0x203ec32b250>,\n",
       " <keras.layers.core.Activation at 0x203ec3e6970>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec406340>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec3e99a0>,\n",
       " <keras.layers.core.Activation at 0x203ec395e80>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec37e970>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec447100>,\n",
       " <keras.layers.core.Activation at 0x203ec446d30>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec343280>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec44cb50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec3e6220>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec4646d0>,\n",
       " <keras.layers.core.Activation at 0x203ec43c730>,\n",
       " <keras.layers.core.Activation at 0x203ec44c160>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec464250>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec4134c0>,\n",
       " <keras.layers.core.Lambda at 0x203ec450970>,\n",
       " <keras.layers.core.Activation at 0x203ec4738e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec473220>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec49af10>,\n",
       " <keras.layers.core.Activation at 0x203ec49aeb0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec4a01f0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec49a070>,\n",
       " <keras.layers.core.Activation at 0x203ec457fa0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec488190>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec494df0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec47efd0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec488fa0>,\n",
       " <keras.layers.core.Activation at 0x203ec464520>,\n",
       " <keras.layers.core.Activation at 0x203ec48c4c0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec44c5e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec46cdf0>,\n",
       " <keras.layers.core.Lambda at 0x203ec3e3bb0>,\n",
       " <keras.layers.core.Activation at 0x203ec44c7f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec44cf40>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec4a9820>,\n",
       " <keras.layers.core.Activation at 0x203ec3e3670>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec4aae20>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec4d3070>,\n",
       " <keras.layers.core.Activation at 0x203ec4bb6d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec4adf70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec4c5d30>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec4a9f40>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec4e18b0>,\n",
       " <keras.layers.core.Activation at 0x203ec457400>,\n",
       " <keras.layers.core.Activation at 0x203ec4e1a90>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec4e10d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec3f1520>,\n",
       " <keras.layers.core.Lambda at 0x203ec5022e0>,\n",
       " <keras.layers.core.Activation at 0x203ec5021c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec457430>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec512220>,\n",
       " <keras.layers.core.Activation at 0x203ec4a9f10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec502430>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec4f0f10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec513250>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec4e1820>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec45ec40>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec4a9490>,\n",
       " <keras.layers.core.Activation at 0x203ec4f5730>,\n",
       " <keras.layers.core.Activation at 0x203ec4e9130>,\n",
       " <keras.layers.core.Activation at 0x203ec513520>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec4f05e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec508b80>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec517be0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec4bbd90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec510700>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec52d220>,\n",
       " <keras.layers.core.Activation at 0x203ec508430>,\n",
       " <keras.layers.core.Activation at 0x203ec4c5280>,\n",
       " <keras.layers.core.Activation at 0x203ec51d8e0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x203ec543190>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec537a90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec54c880>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec560eb0>,\n",
       " <keras.layers.core.Activation at 0x203ec560e20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec5591c0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec537970>,\n",
       " <keras.layers.core.Activation at 0x203ec53f2e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec4e9f70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec5594c0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec53f190>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec3fe5b0>,\n",
       " <keras.layers.core.Activation at 0x203ec525a60>,\n",
       " <keras.layers.core.Activation at 0x203ec567f40>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec4c56a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec5435b0>,\n",
       " <keras.layers.core.Lambda at 0x203ec4aa6a0>,\n",
       " <keras.layers.core.Activation at 0x203ec4fb1c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec4fbfa0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec57cb20>,\n",
       " <keras.layers.core.Activation at 0x203ec5752b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec588610>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec57c070>,\n",
       " <keras.layers.core.Activation at 0x203ec578220>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec573940>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec59d610>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec510100>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec5ad430>,\n",
       " <keras.layers.core.Activation at 0x203ec51dbe0>,\n",
       " <keras.layers.core.Activation at 0x203ec58f9a0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec59d160>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec510f40>,\n",
       " <keras.layers.core.Lambda at 0x203ec5a7fd0>,\n",
       " <keras.layers.core.Activation at 0x203ec59d4f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec5cab20>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec5b9760>,\n",
       " <keras.layers.core.Activation at 0x203ec5b9790>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec5889d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec5961c0>,\n",
       " <keras.layers.core.Activation at 0x203ec5d0190>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec5c0910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec596b50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec5d58b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec578580>,\n",
       " <keras.layers.core.Activation at 0x203ec5d53d0>,\n",
       " <keras.layers.core.Activation at 0x203ec588e80>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec4bfc10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec5b0760>,\n",
       " <keras.layers.core.Lambda at 0x203ec5deb80>,\n",
       " <keras.layers.core.Activation at 0x203ec578d30>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec57c310>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec5f2370>,\n",
       " <keras.layers.core.Activation at 0x203ec5eaeb0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec5e2d00>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec5f9b50>,\n",
       " <keras.layers.core.Activation at 0x203ec5f20a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec5c4a30>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec604550>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec5f24f0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec60cfa0>,\n",
       " <keras.layers.core.Activation at 0x203ec4a90d0>,\n",
       " <keras.layers.core.Activation at 0x203ec5fdd00>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec610760>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec5c43d0>,\n",
       " <keras.layers.core.Lambda at 0x203ec631610>,\n",
       " <keras.layers.core.Activation at 0x203ec631160>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec626940>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec543520>,\n",
       " <keras.layers.core.Activation at 0x203ec620ac0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec620490>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec5e4d90>,\n",
       " <keras.layers.core.Activation at 0x203ec5eaaf0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec62ae20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec5c0e80>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec604d30>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec5de280>,\n",
       " <keras.layers.core.Activation at 0x203ec6103a0>,\n",
       " <keras.layers.core.Activation at 0x203ec5b0130>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec63dc10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec6207c0>,\n",
       " <keras.layers.core.Lambda at 0x203ec657190>,\n",
       " <keras.layers.core.Activation at 0x203ec64b7c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec64bac0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec665610>,\n",
       " <keras.layers.core.Activation at 0x203ec65d1c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec665d60>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec672a00>,\n",
       " <keras.layers.core.Activation at 0x203ec665b50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec64b610>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec682040>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec66f520>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec682340>,\n",
       " <keras.layers.core.Activation at 0x203ec63d160>,\n",
       " <keras.layers.core.Activation at 0x203ec6a3a00>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec6a39d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec687730>,\n",
       " <keras.layers.core.Lambda at 0x203ec68d160>,\n",
       " <keras.layers.core.Activation at 0x203ec6a3be0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec6a36d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec60ca30>,\n",
       " <keras.layers.core.Activation at 0x203ec672940>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec651280>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec5c0490>,\n",
       " <keras.layers.core.Activation at 0x203ec537ee0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec66f400>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec6ae610>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec57c6a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec6bf040>,\n",
       " <keras.layers.core.Activation at 0x203ec68dc40>,\n",
       " <keras.layers.core.Activation at 0x203ec6ae820>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec6b12e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec69ae20>,\n",
       " <keras.layers.core.Lambda at 0x203ec6bf460>,\n",
       " <keras.layers.core.Activation at 0x203ec6d05e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec6d0310>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec6f81c0>,\n",
       " <keras.layers.core.Activation at 0x203ec6dffd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec6ebb80>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec708670>,\n",
       " <keras.layers.core.Activation at 0x203ec708c70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec6d76d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec7028b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec6dfdc0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec702460>,\n",
       " <keras.layers.core.Activation at 0x203ec682b20>,\n",
       " <keras.layers.core.Activation at 0x203ec708580>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec6b9160>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec70f130>,\n",
       " <keras.layers.core.Lambda at 0x203ec6ae460>,\n",
       " <keras.layers.core.Activation at 0x203ec70fe50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec657730>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec6e27c0>,\n",
       " <keras.layers.core.Activation at 0x203ec6b1730>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec5ea7f0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec6daa60>,\n",
       " <keras.layers.core.Activation at 0x203ec717850>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec69a7f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec71e460>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec6653d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec722f40>,\n",
       " <keras.layers.core.Activation at 0x203ec70f070>,\n",
       " <keras.layers.core.Activation at 0x203ec71cdf0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec7285e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec6e22e0>,\n",
       " <keras.layers.core.Lambda at 0x203ec747430>,\n",
       " <keras.layers.core.Activation at 0x203ec72e9d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec73a580>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec758250>,\n",
       " <keras.layers.core.Activation at 0x203ec775b20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec7758b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec752f40>,\n",
       " <keras.layers.core.Activation at 0x203ec7586a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec747d00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec775970>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec73a1f0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec6407c0>,\n",
       " <keras.layers.core.Activation at 0x203ec728880>,\n",
       " <keras.layers.core.Activation at 0x203ec7750d0>,\n",
       " <keras.layers.merge.Concatenate at 0x203ec744550>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec735f70>,\n",
       " <keras.layers.core.Lambda at 0x203ec70f790>,\n",
       " <keras.layers.convolutional.Conv2D at 0x203ec6df970>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x203ec77e2e0>,\n",
       " <keras.layers.core.Activation at 0x203ec747340>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x203ec71e3a0>,\n",
       " <keras.layers.core.Dense at 0x203cd48fcd0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irv2.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "4ldZZ9hF9JOi"
   },
   "outputs": [],
   "source": [
    "#remves the last three layers off\n",
    "#removing upto the flatten layer\n",
    "conv = irv2.layers[-28].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2wHvuS4TyhP",
    "outputId": "e15cc8ec-7e1c-4d7c-d1ab-38ee9c9630e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method KerasTensor.get_shape of <KerasTensor: shape=(None, 8, 8, 192) dtype=float32 (created by layer 'batch_normalization_398')>>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gets the output shape of the last layer\n",
    "conv.get_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TD37XMjwAvr1"
   },
   "source": [
    "##Combining the Soft-Attention layer to the IRV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "4g8yOM857vwU"
   },
   "outputs": [],
   "source": [
    "#conv=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(conv))\n",
    "conv=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(conv))\n",
    "\n",
    "conv  = Activation('relu')(conv)\n",
    "conv = Dropout(0.3)(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "tWLgbvJv73XE"
   },
   "outputs": [],
   "source": [
    "output = Flatten()(conv)\n",
    "output = Dense(7, activation='softmax')(output)\n",
    "model = Model(inputs=irv2.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "B2kf3t26Vscx"
   },
   "outputs": [],
   "source": [
    "#after adding these layers, number of layers = 759"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45terWl_I56N"
   },
   "source": [
    "##Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "gbwcJlW-qoD6"
   },
   "outputs": [],
   "source": [
    "opt1=tf.keras.optimizers.Adam(learning_rate=0.01,epsilon=0.1)\n",
    "model.compile(optimizer=opt1,\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4L7ODmMTRQi"
   },
   "source": [
    "##Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AvJcIwoTV2n",
    "outputId": "e217518a-9f1c-422a-ab45-5c5eac256e70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 149, 149, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 149, 149, 32) 96          conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 149, 149, 32) 0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 147, 147, 32) 9216        activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 147, 147, 32) 96          conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 147, 147, 32) 0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 147, 147, 64) 18432       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 147, 147, 64) 192         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 147, 147, 64) 0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 73, 73, 80)   240         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 73, 73, 80)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 71, 71, 192)  138240      activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 71, 71, 192)  576         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 71, 71, 192)  0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 35, 35, 64)   192         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 35, 35, 64)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 35, 35, 96)   55296       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 35, 35, 48)   144         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 35, 35, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 35, 35, 48)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 35, 35, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 35, 35, 96)   18432       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 35, 35, 64)   76800       activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 35, 35, 96)   82944       activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 35, 35, 64)   12288       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 35, 35, 96)   288         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 35, 35, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 35, 35, 96)   288         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 35, 35, 64)   192         conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 35, 35, 96)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 35, 35, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 35, 35, 96)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 35, 35, 64)   0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 35, 35, 320)  0           activation_208[0][0]             \n",
      "                                                                 activation_210[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "                                                                 activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 35, 35, 32)   96          conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 35, 35, 32)   0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 35, 35, 48)   13824       activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 35, 35, 32)   96          conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 35, 35, 48)   144         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 35, 35, 32)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 35, 35, 48)   0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 35, 35, 32)   9216        activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 35, 35, 64)   27648       activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 35, 35, 32)   96          conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 35, 35, 32)   96          conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 35, 35, 64)   192         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 35, 35, 32)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 35, 35, 32)   0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 35, 35, 64)   0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_215[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 35, 35, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 35, 35, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 35, 35, 32)   96          conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 35, 35, 32)   0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 35, 35, 48)   13824       activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 35, 35, 32)   96          conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 35, 35, 48)   144         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 35, 35, 32)   0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 35, 35, 48)   0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 35, 35, 32)   9216        activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 35, 35, 64)   27648       activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 35, 35, 32)   96          conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 35, 35, 32)   96          conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 35, 35, 64)   192         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 35, 35, 32)   0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 35, 35, 32)   0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 35, 35, 64)   0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_221[0][0]             \n",
      "                                                                 activation_223[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 35, 35, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 35, 35, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 35, 35, 32)   96          conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 35, 35, 32)   0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 35, 35, 48)   13824       activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 35, 35, 32)   96          conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 35, 35, 48)   144         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 35, 35, 32)   0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 35, 35, 48)   0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 35, 35, 32)   9216        activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 35, 35, 64)   27648       activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 35, 35, 32)   96          conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 35, 35, 32)   96          conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 35, 35, 64)   192         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 35, 35, 32)   0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 35, 35, 32)   0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 35, 35, 64)   0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_227[0][0]             \n",
      "                                                                 activation_229[0][0]             \n",
      "                                                                 activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 35, 35, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 35, 35, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 35, 35, 32)   96          conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 35, 35, 32)   0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 35, 35, 48)   13824       activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 35, 35, 32)   96          conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 35, 35, 48)   144         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 35, 35, 32)   0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 35, 35, 48)   0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 35, 35, 32)   9216        activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 35, 35, 64)   27648       activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 35, 35, 32)   96          conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 35, 35, 32)   96          conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 35, 35, 64)   192         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 35, 35, 32)   0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 35, 35, 32)   0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 35, 35, 64)   0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_233[0][0]             \n",
      "                                                                 activation_235[0][0]             \n",
      "                                                                 activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 35, 35, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 35, 35, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 35, 35, 32)   96          conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 35, 35, 32)   0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 35, 35, 48)   13824       activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 35, 35, 32)   96          conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 35, 35, 48)   144         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 35, 35, 32)   0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 35, 35, 48)   0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 35, 35, 32)   9216        activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 35, 35, 64)   27648       activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 35, 35, 32)   96          conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 35, 35, 32)   96          conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 35, 35, 64)   192         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 35, 35, 32)   0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 35, 35, 32)   0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 35, 35, 64)   0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_239[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 35, 35, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 35, 35, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 35, 35, 32)   96          conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 35, 35, 32)   0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 35, 35, 48)   13824       activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 35, 35, 32)   96          conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 35, 35, 48)   144         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 35, 35, 32)   0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 35, 35, 48)   0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 35, 35, 32)   9216        activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 35, 35, 64)   27648       activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 35, 35, 32)   96          conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 35, 35, 32)   96          conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 35, 35, 64)   192         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 35, 35, 32)   0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 35, 35, 32)   0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 35, 35, 64)   0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_245[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "                                                                 activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 35, 35, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 35, 35, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 35, 35, 32)   96          conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 35, 35, 32)   0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 35, 35, 48)   13824       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 35, 35, 32)   96          conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 35, 35, 48)   144         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 35, 35, 32)   0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 35, 35, 48)   0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 35, 35, 32)   9216        activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 35, 35, 64)   27648       activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 35, 35, 32)   96          conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 35, 35, 32)   96          conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 35, 35, 64)   192         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 35, 35, 32)   0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 35, 35, 32)   0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 35, 35, 64)   0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_251[0][0]             \n",
      "                                                                 activation_253[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 35, 35, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 35, 35, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 35, 35, 32)   96          conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 35, 35, 32)   0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 35, 35, 48)   13824       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 35, 35, 32)   96          conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 35, 35, 48)   144         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 35, 35, 32)   0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 35, 35, 48)   0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 35, 35, 32)   9216        activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 35, 35, 64)   27648       activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 35, 35, 32)   96          conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 35, 35, 32)   96          conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 35, 35, 64)   192         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 35, 35, 32)   0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 35, 35, 32)   0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 35, 35, 64)   0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_257[0][0]             \n",
      "                                                                 activation_259[0][0]             \n",
      "                                                                 activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 35, 35, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 35, 35, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 35, 35, 32)   96          conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 35, 35, 32)   0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 35, 35, 48)   13824       activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 35, 35, 32)   96          conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 35, 35, 48)   144         conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 35, 35, 32)   0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 35, 35, 48)   0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 35, 35, 32)   9216        activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 35, 35, 64)   27648       activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 35, 35, 32)   96          conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 35, 35, 32)   96          conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 35, 35, 64)   192         conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 35, 35, 32)   0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 35, 35, 32)   0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 35, 35, 64)   0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_263[0][0]             \n",
      "                                                                 activation_265[0][0]             \n",
      "                                                                 activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 35, 35, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 35, 35, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 35, 35, 32)   96          conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 35, 35, 32)   0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 35, 35, 48)   13824       activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 35, 35, 32)   96          conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 35, 35, 48)   144         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 35, 35, 32)   0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 35, 35, 48)   0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 35, 35, 32)   9216        activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 35, 35, 64)   27648       activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 35, 35, 32)   96          conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 35, 35, 32)   96          conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 35, 35, 64)   192         conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 35, 35, 32)   0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 35, 35, 32)   0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 35, 35, 64)   0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 35, 35, 128)  0           activation_269[0][0]             \n",
      "                                                                 activation_271[0][0]             \n",
      "                                                                 activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 35, 35, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 35, 35, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 35, 35, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 35, 35, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 35, 35, 256)  768         conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 35, 35, 256)  0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 35, 35, 256)  589824      activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 35, 35, 256)  768         conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 35, 35, 256)  0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 17, 17, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 17, 17, 384)  884736      activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 17, 17, 384)  1152        conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 17, 17, 384)  1152        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 17, 17, 384)  0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 17, 17, 384)  0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 17, 17, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 17, 17, 1088) 0           activation_275[0][0]             \n",
      "                                                                 activation_278[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 17, 17, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 17, 17, 128)  384         conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 17, 17, 128)  0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 17, 17, 160)  143360      activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 17, 17, 160)  480         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 17, 17, 160)  0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 17, 17, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 17, 17, 192)  215040      activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 17, 17, 192)  576         conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 17, 17, 192)  576         conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 17, 17, 192)  0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 17, 17, 192)  0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_279[0][0]             \n",
      "                                                                 activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 17, 17, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 17, 17, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 17, 17, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 17, 17, 128)  384         conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 17, 17, 128)  0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 17, 17, 160)  143360      activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 17, 17, 160)  480         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 17, 17, 160)  0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 17, 17, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 17, 17, 192)  215040      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 17, 17, 192)  576         conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 17, 17, 192)  576         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 17, 17, 192)  0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 17, 17, 192)  0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_283[0][0]             \n",
      "                                                                 activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 17, 17, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 17, 17, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 17, 17, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 17, 17, 128)  384         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 17, 17, 128)  0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 17, 17, 160)  143360      activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 17, 17, 160)  480         conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 17, 17, 160)  0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 17, 17, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 17, 17, 192)  215040      activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 17, 17, 192)  576         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 17, 17, 192)  576         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 17, 17, 192)  0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 17, 17, 192)  0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_287[0][0]             \n",
      "                                                                 activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 17, 17, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 17, 17, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 17, 17, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 17, 17, 128)  384         conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 17, 17, 128)  0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 17, 17, 160)  143360      activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 17, 17, 160)  480         conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 17, 17, 160)  0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 17, 17, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 17, 17, 192)  215040      activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 17, 17, 192)  576         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 17, 17, 192)  576         conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 17, 17, 192)  0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 17, 17, 192)  0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_291[0][0]             \n",
      "                                                                 activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 17, 17, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 17, 17, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 17, 17, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 17, 17, 128)  384         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 17, 17, 128)  0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 17, 17, 160)  143360      activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 17, 17, 160)  480         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 17, 17, 160)  0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 17, 17, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 17, 17, 192)  215040      activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 17, 17, 192)  576         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 17, 17, 192)  576         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 17, 17, 192)  0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 17, 17, 192)  0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_295[0][0]             \n",
      "                                                                 activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 17, 17, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 17, 17, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 17, 17, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 17, 17, 128)  384         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 17, 17, 128)  0           batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 17, 17, 160)  143360      activation_300[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 17, 17, 160)  480         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 17, 17, 160)  0           batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 17, 17, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 17, 17, 192)  215040      activation_301[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 17, 17, 192)  576         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 17, 17, 192)  576         conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 17, 17, 192)  0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 17, 17, 192)  0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_299[0][0]             \n",
      "                                                                 activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 17, 17, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 17, 17, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 17, 17, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 17, 17, 128)  384         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 17, 17, 128)  0           batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 17, 17, 160)  143360      activation_304[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 17, 17, 160)  480         conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 17, 17, 160)  0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 17, 17, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 17, 17, 192)  215040      activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 17, 17, 192)  576         conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 17, 17, 192)  576         conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 17, 17, 192)  0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 17, 17, 192)  0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_303[0][0]             \n",
      "                                                                 activation_306[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 17, 17, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 17, 17, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 17, 17, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 17, 17, 128)  384         conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 17, 17, 128)  0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 17, 17, 160)  143360      activation_308[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 17, 17, 160)  480         conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 17, 17, 160)  0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 17, 17, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 17, 17, 192)  215040      activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 17, 17, 192)  576         conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 17, 17, 192)  576         conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 17, 17, 192)  0           batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 17, 17, 192)  0           batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_307[0][0]             \n",
      "                                                                 activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 17, 17, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 17, 17, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 17, 17, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 17, 17, 128)  384         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 17, 17, 128)  0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 17, 17, 160)  143360      activation_312[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 17, 17, 160)  480         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 17, 17, 160)  0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 17, 17, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 17, 17, 192)  215040      activation_313[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 17, 17, 192)  576         conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 17, 17, 192)  576         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 17, 17, 192)  0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 17, 17, 192)  0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_311[0][0]             \n",
      "                                                                 activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 17, 17, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 17, 17, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 17, 17, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 17, 17, 128)  384         conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 17, 17, 128)  0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 17, 17, 160)  143360      activation_316[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 17, 17, 160)  480         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 17, 17, 160)  0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 17, 17, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 17, 17, 192)  215040      activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 17, 17, 192)  576         conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 17, 17, 192)  576         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 17, 17, 192)  0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 17, 17, 192)  0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_315[0][0]             \n",
      "                                                                 activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 17, 17, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 17, 17, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 17, 17, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 17, 17, 128)  384         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 17, 17, 128)  0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 17, 17, 160)  143360      activation_320[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 17, 17, 160)  480         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 17, 17, 160)  0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 17, 17, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 17, 17, 192)  215040      activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 17, 17, 192)  576         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 17, 17, 192)  576         conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 17, 17, 192)  0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 17, 17, 192)  0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_319[0][0]             \n",
      "                                                                 activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 17, 17, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 17, 17, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 17, 17, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 17, 17, 128)  384         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 17, 17, 128)  0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 17, 17, 160)  143360      activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 17, 17, 160)  480         conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 17, 17, 160)  0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 17, 17, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 17, 17, 192)  215040      activation_325[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 17, 17, 192)  576         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 17, 17, 192)  576         conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 17, 17, 192)  0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 17, 17, 192)  0           batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_323[0][0]             \n",
      "                                                                 activation_326[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 17, 17, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 17, 17, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 17, 17, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 17, 17, 128)  384         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 17, 17, 128)  0           batch_normalization_328[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 17, 17, 160)  143360      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, 17, 17, 160)  480         conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 17, 17, 160)  0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 17, 17, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 17, 17, 192)  215040      activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 17, 17, 192)  576         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, 17, 17, 192)  576         conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 17, 17, 192)  0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 17, 17, 192)  0           batch_normalization_330[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_327[0][0]             \n",
      "                                                                 activation_330[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 17, 17, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 17, 17, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 17, 17, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 17, 17, 128)  384         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, 17, 17, 128)  0           batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 17, 17, 160)  143360      activation_332[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 17, 17, 160)  480         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, 17, 17, 160)  0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 17, 17, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 17, 17, 192)  215040      activation_333[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, 17, 17, 192)  576         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 17, 17, 192)  576         conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 17, 17, 192)  0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, 17, 17, 192)  0           batch_normalization_334[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_331[0][0]             \n",
      "                                                                 activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 17, 17, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 17, 17, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 17, 17, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, 17, 17, 128)  384         conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, 17, 17, 128)  0           batch_normalization_336[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 17, 17, 160)  143360      activation_336[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, 17, 17, 160)  480         conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, 17, 17, 160)  0           batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 17, 17, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 17, 17, 192)  215040      activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 17, 17, 192)  576         conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, 17, 17, 192)  576         conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 17, 17, 192)  0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, 17, 17, 192)  0           batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_335[0][0]             \n",
      "                                                                 activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 17, 17, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 17, 17, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 17, 17, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, 17, 17, 128)  384         conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 17, 17, 128)  0           batch_normalization_340[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 17, 17, 160)  143360      activation_340[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, 17, 17, 160)  480         conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, 17, 17, 160)  0           batch_normalization_341[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 17, 17, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 17, 17, 192)  215040      activation_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, 17, 17, 192)  576         conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, 17, 17, 192)  576         conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, 17, 17, 192)  0           batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 17, 17, 192)  0           batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_339[0][0]             \n",
      "                                                                 activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 17, 17, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 17, 17, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 17, 17, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, 17, 17, 128)  384         conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 17, 17, 128)  0           batch_normalization_344[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 17, 17, 160)  143360      activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, 17, 17, 160)  480         conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 17, 17, 160)  0           batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 17, 17, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 17, 17, 192)  215040      activation_345[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, 17, 17, 192)  576         conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, 17, 17, 192)  576         conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 17, 17, 192)  0           batch_normalization_343[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 17, 17, 192)  0           batch_normalization_346[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_343[0][0]             \n",
      "                                                                 activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 17, 17, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 17, 17, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 17, 17, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, 17, 17, 128)  384         conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 17, 17, 128)  0           batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 17, 17, 160)  143360      activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchN (None, 17, 17, 160)  480         conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 17, 17, 160)  0           batch_normalization_349[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 17, 17, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 17, 17, 192)  215040      activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, 17, 17, 192)  576         conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, 17, 17, 192)  576         conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 17, 17, 192)  0           batch_normalization_347[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 17, 17, 192)  0           batch_normalization_350[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_347[0][0]             \n",
      "                                                                 activation_350[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 17, 17, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 17, 17, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 17, 17, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchN (None, 17, 17, 128)  384         conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 17, 17, 128)  0           batch_normalization_352[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 17, 17, 160)  143360      activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_353 (BatchN (None, 17, 17, 160)  480         conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, 17, 17, 160)  0           batch_normalization_353[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 17, 17, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 17, 17, 192)  215040      activation_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchN (None, 17, 17, 192)  576         conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchN (None, 17, 17, 192)  576         conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 17, 17, 192)  0           batch_normalization_351[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 17, 17, 192)  0           batch_normalization_354[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_351[0][0]             \n",
      "                                                                 activation_354[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 17, 17, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 17, 17, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 17, 17, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_356 (BatchN (None, 17, 17, 128)  384         conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, 17, 17, 128)  0           batch_normalization_356[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 17, 17, 160)  143360      activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_357 (BatchN (None, 17, 17, 160)  480         conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, 17, 17, 160)  0           batch_normalization_357[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 17, 17, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 17, 17, 192)  215040      activation_357[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_355 (BatchN (None, 17, 17, 192)  576         conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_358 (BatchN (None, 17, 17, 192)  576         conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, 17, 17, 192)  0           batch_normalization_355[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, 17, 17, 192)  0           batch_normalization_358[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_355[0][0]             \n",
      "                                                                 activation_358[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 17, 17, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 17, 17, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_363 (BatchN (None, 17, 17, 256)  768         conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, 17, 17, 256)  0           batch_normalization_363[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 17, 17, 288)  663552      activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_359 (BatchN (None, 17, 17, 256)  768         conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchN (None, 17, 17, 256)  768         conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_364 (BatchN (None, 17, 17, 288)  864         conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, 17, 17, 256)  0           batch_normalization_359[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 17, 17, 256)  0           batch_normalization_361[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 17, 17, 288)  0           batch_normalization_364[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 8, 8, 384)    884736      activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 8, 8, 288)    663552      activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, 8, 8, 320)    829440      activation_364[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchN (None, 8, 8, 384)    1152        conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_362 (BatchN (None, 8, 8, 288)    864         conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_365 (BatchN (None, 8, 8, 320)    960         conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 8, 8, 384)    0           batch_normalization_360[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, 8, 8, 288)    0           batch_normalization_362[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, 8, 8, 320)    0           batch_normalization_365[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 8, 8, 2080)   0           activation_360[0][0]             \n",
      "                                                                 activation_362[0][0]             \n",
      "                                                                 activation_365[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_367 (BatchN (None, 8, 8, 192)    576         conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, 8, 8, 192)    0           batch_normalization_367[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, 8, 8, 224)    129024      activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_368 (BatchN (None, 8, 8, 224)    672         conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 8, 8, 224)    0           batch_normalization_368[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, 8, 8, 256)    172032      activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_366 (BatchN (None, 8, 8, 192)    576         conv2d_366[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchN (None, 8, 8, 256)    768         conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, 8, 8, 192)    0           batch_normalization_366[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 8, 8, 256)    0           batch_normalization_369[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_366[0][0]             \n",
      "                                                                 activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 8, 8, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 8, 8, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchN (None, 8, 8, 192)    576         conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 8, 8, 192)    0           batch_normalization_371[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 8, 8, 224)    129024      activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchN (None, 8, 8, 224)    672         conv2d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 8, 8, 224)    0           batch_normalization_372[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 8, 8, 256)    172032      activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchN (None, 8, 8, 192)    576         conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_373 (BatchN (None, 8, 8, 256)    768         conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 8, 8, 192)    0           batch_normalization_370[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 8, 8, 256)    0           batch_normalization_373[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_370[0][0]             \n",
      "                                                                 activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 8, 8, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 8, 8, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchN (None, 8, 8, 192)    576         conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 8, 8, 192)    0           batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 8, 8, 224)    129024      activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_376 (BatchN (None, 8, 8, 224)    672         conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 8, 8, 224)    0           batch_normalization_376[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, 8, 8, 256)    172032      activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchN (None, 8, 8, 192)    576         conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_377 (BatchN (None, 8, 8, 256)    768         conv2d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 8, 8, 192)    0           batch_normalization_374[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_377 (Activation)     (None, 8, 8, 256)    0           batch_normalization_377[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_374[0][0]             \n",
      "                                                                 activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 8, 8, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 8, 8, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_379 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_379 (BatchN (None, 8, 8, 192)    576         conv2d_379[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_379 (Activation)     (None, 8, 8, 192)    0           batch_normalization_379[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_380 (Conv2D)             (None, 8, 8, 224)    129024      activation_379[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_380 (BatchN (None, 8, 8, 224)    672         conv2d_380[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_380 (Activation)     (None, 8, 8, 224)    0           batch_normalization_380[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_378 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_381 (Conv2D)             (None, 8, 8, 256)    172032      activation_380[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_378 (BatchN (None, 8, 8, 192)    576         conv2d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_381 (BatchN (None, 8, 8, 256)    768         conv2d_381[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_378 (Activation)     (None, 8, 8, 192)    0           batch_normalization_378[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_381 (Activation)     (None, 8, 8, 256)    0           batch_normalization_381[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_378[0][0]             \n",
      "                                                                 activation_381[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 8, 8, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 8, 8, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_383 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_383 (BatchN (None, 8, 8, 192)    576         conv2d_383[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_383 (Activation)     (None, 8, 8, 192)    0           batch_normalization_383[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_384 (Conv2D)             (None, 8, 8, 224)    129024      activation_383[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_384 (BatchN (None, 8, 8, 224)    672         conv2d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_384 (Activation)     (None, 8, 8, 224)    0           batch_normalization_384[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_382 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_385 (Conv2D)             (None, 8, 8, 256)    172032      activation_384[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_382 (BatchN (None, 8, 8, 192)    576         conv2d_382[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_385 (BatchN (None, 8, 8, 256)    768         conv2d_385[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_382 (Activation)     (None, 8, 8, 192)    0           batch_normalization_382[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_385 (Activation)     (None, 8, 8, 256)    0           batch_normalization_385[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_382[0][0]             \n",
      "                                                                 activation_385[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 8, 8, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 8, 8, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_387 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_387 (BatchN (None, 8, 8, 192)    576         conv2d_387[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_387 (Activation)     (None, 8, 8, 192)    0           batch_normalization_387[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_388 (Conv2D)             (None, 8, 8, 224)    129024      activation_387[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_388 (BatchN (None, 8, 8, 224)    672         conv2d_388[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_388 (Activation)     (None, 8, 8, 224)    0           batch_normalization_388[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_386 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_389 (Conv2D)             (None, 8, 8, 256)    172032      activation_388[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_386 (BatchN (None, 8, 8, 192)    576         conv2d_386[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_389 (BatchN (None, 8, 8, 256)    768         conv2d_389[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_386 (Activation)     (None, 8, 8, 192)    0           batch_normalization_386[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_389 (Activation)     (None, 8, 8, 256)    0           batch_normalization_389[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_386[0][0]             \n",
      "                                                                 activation_389[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 8, 8, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 8, 8, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_391 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_391 (BatchN (None, 8, 8, 192)    576         conv2d_391[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_391 (Activation)     (None, 8, 8, 192)    0           batch_normalization_391[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_392 (Conv2D)             (None, 8, 8, 224)    129024      activation_391[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_392 (BatchN (None, 8, 8, 224)    672         conv2d_392[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_392 (Activation)     (None, 8, 8, 224)    0           batch_normalization_392[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_390 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_393 (Conv2D)             (None, 8, 8, 256)    172032      activation_392[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_390 (BatchN (None, 8, 8, 192)    576         conv2d_390[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_393 (BatchN (None, 8, 8, 256)    768         conv2d_393[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_390 (Activation)     (None, 8, 8, 192)    0           batch_normalization_390[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_393 (Activation)     (None, 8, 8, 256)    0           batch_normalization_393[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_390[0][0]             \n",
      "                                                                 activation_393[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 8, 8, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 8, 8, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_395 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_395 (BatchN (None, 8, 8, 192)    576         conv2d_395[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_395 (Activation)     (None, 8, 8, 192)    0           batch_normalization_395[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_396 (Conv2D)             (None, 8, 8, 224)    129024      activation_395[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_396 (BatchN (None, 8, 8, 224)    672         conv2d_396[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_396 (Activation)     (None, 8, 8, 224)    0           batch_normalization_396[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_394 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_397 (Conv2D)             (None, 8, 8, 256)    172032      activation_396[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_394 (BatchN (None, 8, 8, 192)    576         conv2d_394[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_397 (BatchN (None, 8, 8, 256)    768         conv2d_397[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_394 (Activation)     (None, 8, 8, 192)    0           batch_normalization_394[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_397 (Activation)     (None, 8, 8, 256)    0           batch_normalization_397[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_394[0][0]             \n",
      "                                                                 activation_397[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 8, 8, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 8, 8, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_398 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_398 (BatchN (None, 8, 8, 192)    576         conv2d_398[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 4, 4, 192)    0           batch_normalization_398[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_406 (Activation)     (None, 4, 4, 192)    0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4, 4, 192)    0           activation_406[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3072)         0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 7)            21511       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,486,119\n",
      "Trainable params: 47,431,719\n",
      "Non-trainable params: 54,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rY4gay-StNu"
   },
   "source": [
    "#Model Evaluation Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "fmht9YoYS81h"
   },
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "#taking predictions from the trained model against the test images\n",
    "predictions = model.predict(test_batches, steps=len(test_df)/batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMZ3CTyjS9tK",
    "outputId": "8a22ea9f-a988-49e8-ccf4-789e23407293"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report BEFORE TRAINING for all 7 calsses :\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.00      0.00      0.00        23\n",
      "         bcc       0.04      0.31      0.07        26\n",
      "         bkl       0.06      0.02      0.02        66\n",
      "          df       0.01      0.17      0.01         6\n",
      "         mel       0.05      0.03      0.04        34\n",
      "          nv       0.80      0.50      0.62       663\n",
      "        vasc       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.41       828\n",
      "   macro avg       0.14      0.15      0.11       828\n",
      "weighted avg       0.65      0.41      0.50       828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#geting predictions on test dataset\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "#getting the true labels per image \n",
    "y_true = test_batches.classes\n",
    "\n",
    "\n",
    "\n",
    "# Creating classification report \n",
    "report = classification_report(y_true, y_pred, target_names=targetnames)\n",
    "\n",
    "print(\"\\nClassification Report BEFORE TRAINING for all 7 calsses :\")\n",
    "print(\"\\n\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cW_ZAJADKME2"
   },
   "source": [
    "#Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "ambVEi-7qszi"
   },
   "outputs": [],
   "source": [
    "class_weights = {   \n",
    "                    0 : 1.0,  ## akiec\n",
    "                    1 : 1.0,  ## bcc\n",
    "                    2 : 1.0,  ## bkl\n",
    "                    3 : 1.0,  ## df\n",
    "                    4 : 5.0,  ## mel\n",
    "                    5 : 1.0,  ## nv\n",
    "                    6 : 1.0,  ## vasc\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "1qdMR4cmZPFg"
   },
   "outputs": [],
   "source": [
    "checkpoint_path =path+'Callbacks\\\\IRV2_CP.cpkt'\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "Earlystop = EarlyStopping(monitor='val_loss', mode='min',patience=2, min_delta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "KGkYgZr7XPxU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x203f9a68fd0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcfFpSnSqxYZ",
    "outputId": "0ba17015-57a1-43b7-ec71-7c7c3bbc04d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "233/287 [=======================>......] - ETA: 3:58 - loss: 5.1425 - accuracy: 0.2023"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "\n",
    "history = model.fit(train_batches,\n",
    "                    steps_per_epoch=(len(train_df)/batch_size),\n",
    "                    epochs=15,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=test_batches,\n",
    "                    validation_steps=len(test_df)/batch_size,\n",
    "                    callbacks=[cp_callback,Earlystop],\n",
    "                    class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "Er4sctQOGIdq"
   },
   "outputs": [],
   "source": [
    "model.save(path+'IRV2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxncfFXWKaHu"
   },
   "source": [
    "#Model Evaluation after Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "KO7d7b1pNf_L"
   },
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "#taking predictions from the trained model against the test images\n",
    "predictions = model.predict(test_batches, steps=len(test_df)/batch_size, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYfwEQE4OCgA",
    "outputId": "d34c6281-47b7-4b08-c968-1307b9061587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report AFTER TRAINING for all 7 calsses :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.77      0.43      0.56        23\n",
      "         bcc       0.67      0.54      0.60        26\n",
      "         bkl       0.52      0.77      0.62        66\n",
      "          df       0.60      0.50      0.55         6\n",
      "         mel       0.53      0.59      0.56        34\n",
      "          nv       0.97      0.94      0.95       663\n",
      "        vasc       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.88       828\n",
      "   macro avg       0.72      0.68      0.69       828\n",
      "weighted avg       0.90      0.88      0.89       828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#geting predictions on test dataset\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "#getting the true labels per image \n",
    "y_true = test_batches.classes\n",
    "\n",
    "\n",
    "\n",
    "# Creating classification report \n",
    "report = classification_report(y_true, y_pred, target_names=targetnames)\n",
    "\n",
    "print(\"\\nClassification Report AFTER TRAINING for all 7 calsses :\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cowffDOyQpCK"
   },
   "source": [
    "#Converting the model to a TfLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lu6ChE3iQoWM",
    "outputId": "0fb0ea47-00d3-455f-eeee-0cb53df375f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\JANIDU~1\\AppData\\Local\\Temp\\tmpt10147wp\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert Keras model to TF Lite format using quantization.\n",
    "#Quantization is the process of mapping continuous infinite values to a smaller set of discrete finite values\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eck6Eln4RIc6",
    "outputId": "a4648720-5390-493d-cdc4-467ed8acd106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.88665771484375\n"
     ]
    }
   ],
   "source": [
    "# Show model size in MBs.\n",
    "quantized_model_size = len(tflite_quantized_model) /1024/1024\n",
    "print(quantized_model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "3WXkvk85RNHA",
    "outputId": "434736bf-d52d-4251-c675-1bdb451043db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRV2.tflite has been downloaded\n"
     ]
    }
   ],
   "source": [
    "# Save the quantized model to files Downloads directory\n",
    "f = open('IRV2.tflite', \"wb\")\n",
    "f.write(tflite_quantized_model)\n",
    "f.close()\n",
    "\n",
    "# Download the skin cancer classification model\n",
    "#from google.colab import files\n",
    "#files.download('IRV2.tflite')\n",
    "\n",
    "print('IRV2.tflite has been downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OkF7y2eiYdH"
   },
   "source": [
    "#Taking Cancer Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "5uW7PNoVibIs",
    "outputId": "304dfd95-f874-4f8b-e885-c4e35c7a4adc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_path=path+'train_dir\\\\bcc\\\\_0_212020.jpg'\n",
    "img = image.load_img(image_path, target_size=(299, 299))\n",
    "plt.imshow(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "result=model.predict(img)\n",
    "plt.title((result[0][2]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "SDGP CNN Model - IRV2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
